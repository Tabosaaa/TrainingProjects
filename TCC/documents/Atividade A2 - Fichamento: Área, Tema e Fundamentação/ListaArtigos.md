1. M. A. K. Azad, N. Iqbal, F. Hassan, and P. Roy, "An Empirical Study of High Performance Computing (HPC) Performance Bugs," in *2023 IEEE/ACM 20th International Conference on Mining Software Repositories (MSR)*, Melbourne, Australia, 2023, pp. 194-206. doi: [10.1109/MSR59073.2023.00037](https://doi.org/10.1109/MSR59073.2023.00037)

2. C. Niu, T. Zhang, C. Li, B. Luo, and V. Ng, "On Evaluating the Efficiency of Source Code Generated by LLMs," in *2024 IEEE/ACM First International Conference on AI Foundation Models and Software Engineering (Forge)*, Lisbon, Portugal, 2024, pp. 103-107. doi: [10.1145/3650105.3652295](https://doi.org/10.1145/3650105.3652295)

3. Yang Z, Wang C, Shi J, Hoang T, Kochhar P, Lu Q, Xing Z, Lo D, “What Do Users Ask in Open-Source AI Repositories? An Empirical Study of GitHub Issues,” in 2023 IEEE/ACM 20th International Conference on Mining Software Repositories (MSR), Melbourne, Australia, 2023, pp. 79-91. doi: [10.1109/MSR59073.2023.00024](https://www.computer.org/csdl/proceedings-article/msr/2023/118400a079/1OIKWH0ClEc)

4. D. J. Mankowitz, A. Michi, A. Zhernov, M. Gelmi, M. Selvi, C. Paduraru, E. Leurent, S. Iqbal, J.-B. Lespiau, A. Ahern, et al., "Faster sorting algorithms discovered using deep reinforcement learning," in *Nature*, vol. 618, pp. 257-263, June 2023. doi: [10.1038/s41586-023-06004-9](https://doi.org/10.1038/s41586-023-06004-9)

5. A. Fawzi, M. Balog, A. Huang, T. Hubert, B. Romera-Paredes, M. Barekatain, A. Novikov, F. J. R. Ruiz, J. Schrittwieser, G. Swirszcz, D. Silver, D. Hassabis, and P. Kohli, "Discovering faster matrix multiplication algorithms with reinforcement learning," in *Nature*, vol. 610, pp. 47-53, Oct. 2022. doi: [10.1038/s41586-022-05172-4](https://doi.org/10.1038/s41586-022-05172-4)

6. T. Kraska, A. Beutel, E. H. Chi, J. Dean, and N. Polyzotis, "The Case for Learned Index Structures," in *Proc. 2018 ACM SIGMOD International Conference on Management of Data (SIGMOD '18)*, Houston, TX, USA, 2018, pp. 489-504. doi: [10.1145/3183713.3196909](https://doi.org/10.1145/3183713.3196909)

7. A. Ecoffet, J. Huizinga, J. Lehman, et al., "First return, then explore," in *Nature*, vol. 590, pp. 580-586, 2021. doi: [10.1038/s41586-020-03157-9](https://doi.org/10.1038/s41586-020-03157-9)

8. X. Ma, S. Y. Zhao, Z. H. Yin, et al., "Clustered Reinforcement Learning," in *Frontiers of Computer Science*, vol. 19, p. 194313, 2025. doi: [10.1007/s11704-024-3194-1](https://doi.org/10.1007/s11704-024-3194-1)

9. V. Mnih, K. Kavukcuoglu, D. Silver, A. Graves, I. Antonoglou, D. Wierstra, and M. Riedmiller, "Playing Atari with Deep Reinforcement Learning," *arXiv preprint*, 2013. Disponível em: [https://arxiv.org/abs/1312.5602](https://arxiv.org/abs/1312.5602)

10. Kool W, Hoof H.V, Welling M, "Attention, Learn to Solve Routing Problems!" in *International Conference on Learning Representations*, 2018. Disponível em: [https://api.semanticscholar.org/CorpusID:59608816](https://api.semanticscholar.org/CorpusID:59608816).

11. Gasse M, Chételat D, Ferroni N, Charlin L, Lodi A, “Exact Combinatorial Optimization with Graph Convolutional Neural Networks,” in Proceedings of the 33rd International Conference on Neural Information Processing Systems, 2019. Disponível em: https://dl.acm.org/doi/10.5555/3454287.3455683

12. Y. Li, D. Choi, J. Chung, N. Kushman, J. Schrittwieser, R. Leblond, T. Eccles, J. Keeling, F. Gimeno, A. Dal Lago, T. Hubert, P. Choy, C. de Masson d’Autume, I. Babuschkin, X. Chen, P.-S. Huang, J. Welbl, S. Gowal, A. Cherepanov, J. Molloy, D. J. Mankowitz, E. S. Robson, P. Kohli, N. de Freitas, K. Kavukcuoglu, and O. Vinyals, "Competition-level code generation with AlphaCode," in *Science*, vol. 378, no. 6624, pp. 1092–1097, Dec. 2022. doi: [10.1126/science.abq1158](http://dx.doi.org/10.1126/science.abq1158)

13. Silver D, Hubert T, Schrittwieser J, Antonoglou I, Lai M, Guez A, Lanctot M, Sifre L, Kumaran D, Graepel T, Lillicrap T, Simonyan K, Hassabis D, "A General Reinforcement Learning Algorithm That Masters Chess, Shogi, and Go Through Self-Play," in *Science*, vol. 362, no. 6419, pp. 1140-1144, Dec. 2018. doi: [10.1126/science.aar6404](https://doi.org/10.1126/science.aar6404).

14. Li H, Qian X, Song W, “Prioritized Experience Replay Based on Dynamics Priority,” in Scientific Reports, vol. 14, p. 6014, 2024. doi: 10.1038/s41598-024-56673-3.

15. Salimans T, Ho J, Chen X, Sutskever I, “Evolution Strategies as a Scalable Alternative to Reinforcement Learning,” arXiv preprint, 2017. doi: 10.48550/arXiv.1703.03864(https://arxiv.org/abs/1703.03864)
